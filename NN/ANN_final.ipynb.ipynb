{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN 돌리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import trange\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = '2016-01-2021-05-31'\n",
    "years = '2020-06-2021-05-31'\n",
    "\n",
    "df = pd.read_csv('./data/' + years + '_all.csv')\n",
    "df['일시'] = df['Unnamed: 0']\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df['일시'] = pd.to_datetime(df['일시'])\n",
    "df.set_index('일시',inplace=True)\n",
    "data = df\n",
    "display(df.head(3))\n",
    "display(df.tail(3))\n",
    "print(df.shape)\n",
    "result = []     # metric 담을 lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, ts:np.array, lookback_size:int, forecast_size:int):\n",
    "    self.lookback_size = lookback_size\n",
    "    self.forecast_size = forecast_size\n",
    "    self.data = ts\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data) - self.lookback_size - self.forecast_size + 1\n",
    "  \n",
    "  def __getitem__(self, i):\n",
    "    idx = (i + self.lookback_size)\n",
    "    look_back = self.data[i:idx]\n",
    "    forecast = self.data[idx:idx + self.forecast_size]\n",
    "    \n",
    "    return look_back, forecast\n",
    "  \n",
    "class Net(nn.Module):\n",
    "  def __init__(self, d_in, d_out, d_hidden, activation=F.relu):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(d_in, d_hidden)\n",
    "    self.lin2 = nn.Linear(d_hidden, d_out)\n",
    "    self.activation = activation\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.lin1(x)\n",
    "    x = self.activation(x)\n",
    "    x = self.lin2(x)\n",
    "    return x # scaled 시 2가지 케이스\n",
    "\n",
    "def mape(y_pred, y_true):\n",
    "  return (np.abs(y_pred - y_true)/y_true).mean() * 100\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "  return np.abs(y_pred - y_true).mean()\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "  return np.mean((np.array(y_true) - np.array(y_pred)) ** 2)\n",
    "\n",
    "def rmse(y_pred, y_true):\n",
    "  return np.sqrt(mse(y_pred, y_true))\n",
    "\n",
    "def r_squared(y_pred, y_true):\n",
    "  return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1년/5년치 데이터에 넣을 ord_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_size = 15, 30, 60, 90\n",
    "# lookback = 5, 15, 30, 90\n",
    "# forecast = 1, 5, 15\n",
    "\n",
    "\n",
    "ord_lst = [[15, 5, 1, 400, 0.0001], [15, 5, 1, 700, 0.0001], [15, 5, 1, 1000, 0.0001]]\n",
    "\n",
    "\n",
    "# ord_lst = [[15, 5, 1, 400, 0.0001], [15, 5, 1, 700, 0.0001], [15, 5, 1, 1000, 0.0001], \n",
    "#            [15, 5, 5, 400, 0.0001], [15, 5, 5, 700, 0.0001], [15, 5, 5, 1000, 0.0001], \n",
    "#            [15, 5, 15, 400, 0.0001], [15, 5, 15, 700, 0.0001], [15, 5, 15, 1000, 0.0001], \n",
    "           \n",
    "#            [30, 5, 1, 400, 0.0001], [30, 5, 1, 700, 0.0001], [30, 5, 1, 1000, 0.0001], \n",
    "#            [30, 5, 5, 400, 0.0001], [30, 5, 5, 700, 0.0001], [30, 5, 5, 1000, 0.0001], \n",
    "#            [30, 5, 15, 400, 0.0001], [30, 5, 15, 700, 0.0001], [30, 5, 15, 1000, 0.0001], \n",
    "               \n",
    "#            [60, 5, 1, 400, 0.0001], [60, 5, 1, 700, 0.0001], [60, 5, 1, 1000, 0.0001], \n",
    "#            [60, 5, 5, 400, 0.0001], [60, 5, 5, 700, 0.0001], [60, 5, 5, 1000, 0.0001], \n",
    "#            [60, 5, 15, 400, 0.0001], [60, 5, 15, 700, 0.0001], [60, 5, 15, 1000, 0.0001], \n",
    "      \n",
    "#            [90, 5, 1, 400, 0.0001], [90, 5, 1, 700, 0.0001], [90, 5, 1, 1000, 0.0001], \n",
    "#            [90, 5, 5, 400, 0.0001], [90, 5, 5, 700, 0.0001], [90, 5, 5, 1000, 0.0001], \n",
    "#            [90, 5, 15, 400, 0.0001], [90, 5, 15, 700, 0.0001], [90, 5, 15, 1000, 0.0001]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장하며 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_size, lookback_size, forecast_size, epoch, lr in ord_lst:\n",
    "\tprint(pred_size, lookback_size, forecast_size, epoch, lr)\n",
    "\tscaler = MinMaxScaler()\n",
    "\ttrn_scaled = scaler.fit_transform(data[:-pred_size].to_numpy(dtype=np.float32)).flatten()\n",
    "\ttst_scaled = scaler.transform(data[-pred_size-lookback_size:].to_numpy(dtype=np.float32)).flatten()\n",
    "\n",
    "\ttrn_df = data[:-pred_size].to_numpy(dtype=np.float32).flatten()\n",
    "\ttst_df = data[-pred_size - lookback_size:].to_numpy(dtype=np.float32).flatten()\n",
    "\ttst_y = tst_df[-pred_size:]\n",
    "\n",
    "\t### 스케일 안한 케이스\n",
    "\ttrn_Ods = TimeSeriesDataset(trn_df, lookback_size, forecast_size)\n",
    "\ttst_Ods = TimeSeriesDataset(tst_df, lookback_size, forecast_size)\n",
    "\n",
    "\ttrn_Odl = DataLoader(trn_Ods, batch_size=32, shuffle=True)\n",
    "\ttst_Odl = DataLoader(tst_Ods, batch_size=pred_size, shuffle=False)\n",
    "\n",
    "\t#### 스케일 한 케이스\n",
    "\ttrn_ds = TimeSeriesDataset(trn_scaled, lookback_size, forecast_size)\n",
    "\t# tst_ds = TimeSeriesDataset(tst_scaled, lookback_size, forecast_size)\n",
    "\n",
    "\ttrn_dl = DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
    "\t# tst_dl = DataLoader(tst_ds, batch_size=pred_size, shuffle=False)\n",
    "\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tnet = Net(lookback_size, forecast_size, 512)\n",
    "\tnet.to(device)\n",
    "\toptim = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\tpbar = trange(epoch)\n",
    "\tlosses = []\n",
    "\ttrn_losses = []\n",
    "\ttst_rmse_losses = []\n",
    "\n",
    "\tfor i in pbar:\n",
    "\t\tnet.train()\n",
    "\t\ttrn_loss = .0\n",
    "\n",
    "\t\tfor x, y in trn_Odl: # 여기 2가지 케이스\n",
    "\t\t\tx, y = x.to(device), y.to(device)   # (32,15), (32, 5) in 32줄 (총 326개)\n",
    "\t\t\tp = net(x)    # (32, 5)인 predict output\n",
    "\t\t\toptim.zero_grad()\n",
    "\t\t\tloss = F.mse_loss(p, y)   # pred 와 target 차이\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptim.step()\n",
    "\t\t\ttrn_loss += loss.item() * len(y)\n",
    "\t\ttrn_loss = trn_loss / len(trn_Ods) # 여기 2가지 케이스\n",
    "\n",
    "\t\tnet.eval()\n",
    "\t\twith torch.inference_mode():\n",
    "\t\t\tx, y = next(iter(tst_Odl)) # 여기 2가지 케이스\n",
    "\t\t\tx, y = x.to(device), y.to(device)     # x: input(15), y: target(5)\n",
    "\t\t\tp = net(x)                            # p: 예측 값(5)\n",
    "\t\t\ttst_loss = F.mse_loss(p, y) \n",
    "\t\t\ty = y.cpu()\n",
    "\t\t\tp = p.cpu()    \n",
    "\t\t\ttst_mape = mape(p,y)\n",
    "\t\t\ttst_mae = mae(p,y)\n",
    "\t\t\ttst_rmse = rmse(p,y)\n",
    "\t\t\ttst_mse = mse(p,y)\n",
    "\n",
    "\n",
    "\t\tpbar.set_postfix({'trn_loss':trn_loss, 'tst_loss':tst_loss.item(), 'tst_mape':tst_mape.item(), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'tst_mae':tst_mae.item(), 'tst_rmse':tst_rmse.item()})\n",
    "\t\ttst_loss = tst_loss.cpu()  \n",
    "\n",
    "\t\tlosses.append(tst_loss)\n",
    "\t\ttrn_losses.append(trn_loss)\n",
    "\t\ttst_rmse_losses.append(tst_rmse)\n",
    "\n",
    "\tplot_start = 50     # 1부터 하면 훅 떨어지는거 그리느라 뒷부분이 잘 안보여서 확대한 것\n",
    "\tepochs_to_plot = range(plot_start, epoch)\n",
    "\tplt.figure(figsize=(10, 5))\n",
    "\tplt.title(f\"Neural Network_({pred_size},{lookback_size},{forecast_size})_{epoch}_{lr}\")\n",
    "\tplt.plot(epochs_to_plot, losses[plot_start:], label='tst_loss')\n",
    "\tplt.plot(epochs_to_plot, tst_rmse_losses[plot_start:], label='tst_rmse')\n",
    "\tplt.plot(epochs_to_plot, trn_losses[plot_start:], label='train_loss')\n",
    "\tplt.xticks(range(plot_start, epoch, 100))\n",
    "\tplt.legend()\n",
    "\tplt.savefig(f'./fig_ANN/ANN_loss_{years}_({pred_size},{lookback_size},{forecast_size})_{epoch}_{lr}.png')\n",
    "\tplt.show\n",
    "\n",
    "\n",
    "\tpreds = []\n",
    "\tx, y = trn_Ods[len(trn_Ods)-1]  #마지막의 input(15개), output(5개) 값을 가져옴\n",
    "\t# print(f'x: {x}, y: {y}\\n')\n",
    "\n",
    "\tx = torch.tensor(x)\n",
    "\t# print(np.concatenate([x, y]).shape , x.shape, y.shape)\n",
    "\n",
    "\tnet.eval()\n",
    "\tfor _ in range(int(pred_size/forecast_size)):\n",
    "\t\tx = np.concatenate([x, y])[-lookback_size:]   # x = 20개[-15:] 즉, 15개\n",
    "\n",
    "\t\twith torch.inference_mode():    \n",
    "\t\t\ty = net(torch.tensor(x).cuda()).cpu()\n",
    "\t\t\t# print(f'y: {y}')\n",
    "\t\tpreds.append(y)\n",
    "\n",
    "\n",
    "\tpreds = np.concatenate(preds)  # 예측 결과값을 하나의 Numpy 배열로 병합\n",
    "\t# print(f'preds: {preds}')    # 4개(5개씩)를 합치므로 4x5 = 20개\n",
    "\n",
    "\tMAPE = mape(preds,tst_y)\n",
    "\tMAE = mae(preds,tst_y)\n",
    "\tMSE = mse(preds,tst_y)\n",
    "\tRMSE = rmse(preds,tst_y)\n",
    "\tR2 = r_squared(preds,tst_y)\n",
    "\tresult.append([(pred_size, lookback_size, forecast_size, epoch, lr), MAPE, MAE, MSE, RMSE, R2])\n",
    "\n",
    "\tprint(p.shape)\n",
    "\tprint(preds.shape)\n",
    "\tprint(tst_y.shape)\n",
    "\n",
    "\tplt.figure(figsize=(10, 5))\n",
    "\tplt.title(f\"NN_({pred_size},{lookback_size},{forecast_size})_{epoch}_MAPE:{MAPE:.3f}, MAE:{MAE:.3f}, MSE:{MSE:.3f}, RMSE:{RMSE:.3f}, R2:{R2:.3f}\")\n",
    "\tplt.plot(range(pred_size), tst_y, label=\"True\")\n",
    "\tplt.plot(range(pred_size), preds, label=\"Prediction\")\n",
    "\tplt.legend()\n",
    "\tplt.savefig(f'./fig_ANN/ANN_{years}_({pred_size},{lookback_size},{forecast_size})_{epoch}_{lr}_hidden1.png')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:.4f}'.format)\n",
    "result_df = pd.DataFrame(result, columns=['order', 'MAPE', 'MAE', 'MSE', 'RMSE', 'R2'])\n",
    "result_df.set_index('order', inplace=True)\n",
    "result_df.to_csv(f'./result/ANN_result_{years}_hidden1.csv')\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaJung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
